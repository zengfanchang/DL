{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93810bc-2f20-49ff-81e2-3b9618b1456b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeng/anaconda3/envs/torch/lib/python3.11/site-packages/torchvision/models/detection/anchor_utils.py:63: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at /croot/pytorch_1686931851744/work/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(\"cpu\"),\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from IPython import display\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff40f4b2-43f4-4fe9-928f-a32aeebf659e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "tensor(data, *, dtype=None, device=None, requires_grad=False, pin_memory=False) -> Tensor\n",
       "\n",
       "Constructs a tensor with no autograd history (also known as a \"leaf tensor\", see :doc:`/notes/autograd`) by copying :attr:`data`.\n",
       "\n",
       ".. warning::\n",
       "\n",
       "    When working with tensors prefer using :func:`torch.Tensor.clone`,\n",
       "    :func:`torch.Tensor.detach`, and :func:`torch.Tensor.requires_grad_` for\n",
       "    readability. Letting `t` be a tensor, ``torch.tensor(t)`` is equivalent to\n",
       "    ``t.clone().detach()``, and ``torch.tensor(t, requires_grad=True)``\n",
       "    is equivalent to ``t.clone().detach().requires_grad_(True)``.\n",
       "\n",
       ".. seealso::\n",
       "\n",
       "    :func:`torch.as_tensor` preserves autograd history and avoids copies where possible.\n",
       "    :func:`torch.from_numpy` creates a tensor that shares storage with a NumPy array.\n",
       "\n",
       "Args:\n",
       "    data (array_like): Initial data for the tensor. Can be a list, tuple,\n",
       "        NumPy ``ndarray``, scalar, and other types.\n",
       "\n",
       "Keyword args:\n",
       "    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
       "        Default: if ``None``, infers data type from :attr:`data`.\n",
       "    device (:class:`torch.device`, optional): the device of the constructed tensor. If None and data is a tensor\n",
       "        then the device of data is used. If None and data is not a tensor then\n",
       "        the result tensor is constructed on the CPU.\n",
       "    requires_grad (bool, optional): If autograd should record operations on the\n",
       "        returned tensor. Default: ``False``.\n",
       "    pin_memory (bool, optional): If set, returned tensor would be allocated in\n",
       "        the pinned memory. Works only for CPU tensors. Default: ``False``.\n",
       "\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])\n",
       "    tensor([[ 0.1000,  1.2000],\n",
       "            [ 2.2000,  3.1000],\n",
       "            [ 4.9000,  5.2000]])\n",
       "\n",
       "    >>> torch.tensor([0, 1])  # Type inference on data\n",
       "    tensor([ 0,  1])\n",
       "\n",
       "    >>> torch.tensor([[0.11111, 0.222222, 0.3333333]],\n",
       "    ...              dtype=torch.float64,\n",
       "    ...              device=torch.device('cuda:0'))  # creates a double tensor on a CUDA device\n",
       "    tensor([[ 0.1111,  0.2222,  0.3333]], dtype=torch.float64, device='cuda:0')\n",
       "\n",
       "    >>> torch.tensor(3.14159)  # Create a zero-dimensional (scalar) tensor\n",
       "    tensor(3.1416)\n",
       "\n",
       "    >>> torch.tensor([])  # Create an empty tensor (of size (0,))\n",
       "    tensor([])\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.tensor??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee1d3c74-671f-4044-bfb4-a37dfdf946b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import torch\n",
      "import torchvision\n",
      "from IPython import display\n",
      "from d2l import torch as d2l\n",
      "torch.tensor>\n",
      "torch.tensor?\n",
      "torch.tensor??\n",
      "%history\n"
     ]
    }
   ],
   "source": [
    "%history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3a1611f-d914-460f-bc32-54e253938928",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6softmax实现.ipynb  图像数据集.ipynb  线性回归的简洁实现.ipynb\n",
      "图像数据分类.ipynb    线性代数.ipynb    读取数据集.ipynb\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aaa738e-86c8-4ef5-b296-2a6439cb0fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6softmax实现.ipynb  图像数据集.ipynb\t线性回归的简洁实现.ipynb\n",
      "图像数据分类.ipynb    线性代数.ipynb\t读取数据集.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0551c5ed-067f-44c4-88be-230b8b66a4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
